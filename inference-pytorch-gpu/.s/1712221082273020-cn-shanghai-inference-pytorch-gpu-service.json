{
  "statefulConfig": {
    "serviceName": "inference-pytorch-gpu-service",
    "description": "",
    "role": "acs:ram::1712221082273020:role/aliyunfcdefaultrole",
    "logConfig": {
      "project": "",
      "logstore": "",
      "enableRequestMetrics": false,
      "enableInstanceMetrics": false,
      "logBeginRule": "None"
    },
    "serviceId": "17d29114-7acb-4640-b419-741ee8131cf8",
    "createdTime": "2022-12-12T16:27:22Z",
    "lastModifiedTime": "2022-12-13T03:35:07Z",
    "vpcConfig": {
      "vpcId": "",
      "vSwitchIds": [],
      "securityGroupId": "",
      "role": "",
      "anytunnelViaENI": null
    },
    "internetAccess": true,
    "nasConfig": {
      "userId": -1,
      "groupId": -1,
      "mountPoints": []
    },
    "ossMountConfig": {
      "mountPoints": []
    },
    "vendorConfig": null,
    "tracingConfig": {
      "type": null,
      "params": null,
      "jaegerConfig": null
    },
    "name": "inference-pytorch-gpu-service"
  },
  "statefulAutoConfig": {
    "role": "acs:ram::1712221082273020:role/aliyunfcdefaultrole"
  }
}